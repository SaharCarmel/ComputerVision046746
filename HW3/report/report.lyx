#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{polyglossia}
\usepackage{titlesec}
\usepackage{wrapfig}
%\usepackage{pygmentize}
%\usepackage{minted}
\usepackage[all]{xy}
\usepackage[bottom]{footmisc}

\addtolength{\skip\footins}{2pc plus 5pt}

\AtBeginDocument{
\renewcommand\footnoterule{%
  \kern -3pt
  \hbox to \textwidth{\hfill\vrule height 0.4pt width .4\textwidth}
  \kern 2.6pt
}}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams-chap-bytype
\end_modules
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Frank Ruehl CLM"
\font_sans "default" "Simple CLM"
\font_typewriter "default" "Miriam Mono CLM"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 1
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 3cm
\rightmargin 3cm
\bottommargin 3cm
\secnumdepth 3
\tocdepth 2
\paragraph_separation skip
\defskip smallskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\lang english
Computer Vision 046746
\begin_inset Newline newline
\end_inset

HW 03
\end_layout

\begin_layout Standard
\align center

\lang english
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Sahar Carmel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\numeric on
\lang hebrew
305554453
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Nadav Gelfer
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\numeric on
\lang hebrew
304849821
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Section
Classic versus Deep learning-based semantric segmentation
\end_layout

\begin_layout Subsection*
Summary
\end_layout

\begin_layout Standard
In this part we compared the performance of GrabCut, which is a classic
 image segmentation method, with DeepLabv3 which is one of the latest (dec.
 17') deep-learning method.
\end_layout

\begin_layout Standard
We used both algorithms on several pictures depicting different objects
 in different environments and compared the results.
 
\end_layout

\begin_layout Standard
We later used the segmentation to place an animal on the beach and see how
 well our new image is recognized by a pre-trained classifier.
 
\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
The frog images are:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/data/frogs/frog1.jpg
	lyxscale 50
	width 200pt
	height 160pt

\end_inset


\begin_inset space ~
\end_inset


\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/data/frogs/frog2.jpg
	lyxscale 50
	width 200pt
	height 160pt

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Images under /data/frogs
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
And the horses images are:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/data/horses/horse2.jpg
	lyxscale 30
	width 200pt
	height 112.5pt

\end_inset


\begin_inset space ~
\end_inset


\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/data/horses/horse1.png
	lyxscale 50
	width 200pt
	height 112.5pt

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Images under /data/horses
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsubsection*
Classic
\end_layout

\begin_layout Standard
The classic method we've chosen is GrabCut.
 This method required simple pre-processing by finding the coordinates and
 measurements of a rectangle surrounding the object (There are other possible
 ways such as painting the ground and object with different colors, but
 we used the rectangle method).
\end_layout

\begin_layout Standard
The segmentation itself is done via Markov random fields conversion into
 a source-sink graph and using a graph cuts.
\end_layout

\begin_layout Standard
The disadvntage of the method is that is required user pre-processing and
 the advantage is that it allows an approch both from an object rough surroundin
g and from object and background coloring, which allows to better the results
 in rough areas.
\end_layout

\begin_layout Standard
We got the following segmentations:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_gc_frogs_seg.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Segmentations of the frog images using GrabCut
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_gc_horses_seg.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Segmentations of the horse images using GrabCut
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Since GrabCut only classifies a certain pixel as background or foreground,
 we have both segmentations colored the same way: black for background and
 green for foreground (i.e.
 our desired object).
\end_layout

\begin_layout Standard
Using the above segments to isolate the objects, we get: 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_gc_frogs_masked.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Frogs isolated using the segmentation from GrabCut
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can see that he frogs we're recognized mostly fine, besides the eyes
 of the left frog which we're classified as background pixels.
 The right frog did not lose any body parts during the segmentation but
 we did get an extra leaf included.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_gc_horses_masked.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Horses isolated using the segmentation from GrabCut
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The horses segmentation was heavily background dependant.
 We can see that while the right horse (brown on green) was cut almost perfectly
, the left one (white on mostly white) was cut out fine at its top part
 (which was on a green/red background) but pretty badly on its feet which
 were closer in color to the snow.
 
\end_layout

\begin_layout Subsubsection*
Deep Learning
\end_layout

\begin_layout Standard
Our deep-learning based method was DeepLabv3 because of its high success
 rate on the 2012 PASCAL VOC dataset (as shown in tutorial 5).
 The net uses both atrous convolution and ASPP (v3 removed the CRF that
 were introduced in v2).
 
\end_layout

\begin_layout Standard
The disadvantages of the model is that it required training and is a lot
 more complicated than a classic approch.
 The advantages are that it requires no manual pre-processing (requires
 only transforms.ToTensor and transforms.Noramlize).
 The net can also classify a segmented object and give multiple segmented
 objects from a single picture.
\end_layout

\begin_layout Standard
We got the following segmentations:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_deep_frogs_seg.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Segmentations of the frog images using DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
It should be noted that DeepLabv3 does not have frogs as a class.
 Inspecting the model output for these images gives back a 3 for both, which
 translates to a bird.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_deep_horses_seg.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Segmentations of the horse images using DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the horses images the model predicts the segmented object correctly,
 labeling both images as 13, which translates to a horse.
\end_layout

\begin_layout Standard
Using the above segments to isolate the objects, we get:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_deep_frogs_masked.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Frogs isolated using the segmentation from DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Inspecting the results we can see that the left frog lost its right legs
 and some of its left while the right one was cropped with good success,
 but we did get a mispediction due to an object at the bottom of the picture.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q2_deep_horses_masked.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Horses isolated using the segmentation from DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Compared to the frog results, the horses did not lose any limbs during the
 segmentation.
 There are still some rough edges around the horses themselves.
 
\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
The images we used:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/my_data/random_images/q3_cat.jpeg
	lyxscale 50
	scale 50

\end_inset


\begin_inset space ~
\end_inset


\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/my_data/random_images/q3_kindle.jpg
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/use/git/ComputerVision046746/HW3/code/my_data/random_images/q3_tv.jpg
	lyxscale 50
	width 200pt
	height 200pt

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Same cat featured at HW2, a kindle e-reader and a TV
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsubsection*
Classic
\end_layout

\begin_layout Standard
The segmentation output was:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q4_classic_seg.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Segmentations of our images using GrabCut
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Just looking at the segmentations it's obvious that both the tv and the
 kindle were rightly segmented while the cat has a lot of background included.
 Looking at the images themselves:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q4_classic_masked.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Our images isolated using the segmentation from GrabCut
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Indeed the segmentation of both the tv and the kindle were good (funnily
 enough, the text 'kindle' at the bottom of the device was cut out) and
 the cat does have a lot of background included, probably because of the
 Q-tip next to its legs and the stripes of the desk behind him.
\end_layout

\begin_layout Subsubsection*
Deep Learning
\end_layout

\begin_layout Standard
The segmentation output was:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q4_deep_seg.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Segmentations of our images using DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can see that there were multiple classes segmented at the TV image, and
 that both the kindle and the cat recognized a single object.
 Inspecting the model output, we get for the TV image 9, 18 and 20 which
 are chair, sofa and tvmonitor.
 The kindle images yields 15 which is a person and the cat image was recognized
 correclty and returns 8.
\end_layout

\begin_layout Standard
Using the above segments to isolate the objects, we get:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q4_deep_masked.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Our images isolated using the segmentation from DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can see the multiple objects recognized in the TV Image, that the kindle
 was not recognized at all but rather the human holding it and the cat was
 recognized succesfully.
 If we replot the TV image taking only the pixels that were classified as
 TV, we get:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q4_tv_replot.png
	lyxscale 50
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
TV image isolated using the segmentation from DeepLabv3 and using tvmonitor
 class pixels only
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Comparison
\end_layout

\begin_layout Standard
Assuming we filtered the correct TV segmentation using the correct class
 label, the results for that image are mostly identical with a slight advntage
 to the classic method because of its smoother edges.
 
\end_layout

\begin_layout Standard
As for the kindle image, the classic method beats the deep learning big
 time.
 The deep learning method did not recognize the kindle at all but rather
 the human holding it (in which it did a good job, just not the job we wanted
 it to do...) while the classic method gave a great result (even if we don't
 ignore the cropped 'kindle' label from the image).
\end_layout

\begin_layout Standard
The cat demonstrates a great advntage in favor of the deep learning method.
 While the classic method included a lot of 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 inside the rectangle, the deep learning method gave a good cut of the cat
 with little added carpet on the edges.
 
\end_layout

\begin_layout Standard
Judging by the results we deduct that the deep learning yields better results
 when the object we try to segment is one of the classes the network has
 been trained on (which is why it detect a human and not the kindle, contrary
 to the 
\begin_inset Quotes eld
\end_inset

dumb
\begin_inset Quotes erd
\end_inset

 algorithm which just got a rectangle to search in).
 In a loaded environment (such as the TV picture), the deep learning algorithm
 might pick some objects we did not want and so it will require some changes
 to the mask, in order to segment the right object, something we did not
 need to do with the classic method.
\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
We chose VGG16.
\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Using the provided cow.jpg and sheep.jpg, we recieve the following predictions:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q7.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
VGG16's prediction for cow.jpg and sheep.jpg
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
While the model predicted a wrong class for both images, the predicted classes
 are somewhat related to the actual classes.
\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
We chose to segment the cow image:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q8.png
	scale 75

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cow isolated using the segmentation from DeepLabv3
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
The cows having fun at the beach:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q9.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cows on the beach
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
Feeding the new image to VGG16 we get:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/q1/q10.png
	lyxscale 50
	scale 75

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
VGG16's prediction for pasted cow on the beach
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can see that the new prediction is no where near the original prediction
 (They are close only the sense that both predicted classes are animals).
 In VGG16's favor we can say that the cow was resized to fit the beach image
 resolution, which might made it a bit harder to properly classify.
\end_layout

\begin_layout Standard
Another possible reason for the mis-classification is the unnatural habitat.
 Cows aren't usually found on the beach and the background is very different
 from the usual scenario we tend to find cows in.
\end_layout

\begin_layout Section
Jurassic Fishbach
\end_layout

\begin_layout Subsection*
Summary
\end_layout

\begin_layout Standard
...
\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Subsection
\begin_inset space ~
\end_inset


\end_layout

\end_body
\end_document
